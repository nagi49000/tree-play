{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671a0669",
   "metadata": {},
   "source": [
    "# Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f62e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import copy\n",
    "import shap\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b1b286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "df = utils.get_data()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5517a816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348, 3)\n",
      "(348,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df[[\"temp_2\", \"temp_1\", \"average\"]])\n",
    "y = np.array(df[\"actual\"])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e179fb56",
   "metadata": {},
   "source": [
    "### Standard Gradient Boosted trees\n",
    "Based off XGBoost. As for Random Forest, the out-of-the-box values give a mean abs error just below 4 Farenheit (although the errors coming out of the cross-validation show less variance on repeated runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d7c785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-3.79999022, -3.59903   , -3.49938456, -4.29404266, -4.3860435 ]), -3.915698191896193)\n"
     ]
    }
   ],
   "source": [
    "regr = GradientBoostingRegressor()\n",
    "scores = utils.get_cross_val_scores(regr, X, y, 5)\n",
    "print((scores, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba1f86",
   "metadata": {},
   "source": [
    "Tweaking parameters (e.g. min_samples_leaf, min_samples_split) to pull the trees back from overfitting yields some slight performance improvements as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "718056df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-3.98207312, -4.35697679, -3.50835749, -3.77251924, -3.33010732]), -3.7900067899071628)\n"
     ]
    }
   ],
   "source": [
    "regr = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=1.0,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=10,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_depth=3,\n",
    "    min_impurity_decrease=0.0,\n",
    "    max_features=None,\n",
    "    alpha=0.9,\n",
    "    max_leaf_nodes=None,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=None,\n",
    "    tol=1.0e-4,\n",
    "    ccp_alpha=0.0\n",
    ")\n",
    "scores = utils.get_cross_val_scores(regr, X, y, 5)\n",
    "print((scores, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0579fd4",
   "metadata": {},
   "source": [
    "### LightGBM Gradient Boosted Trees\n",
    "Based on LightGBM. As for Random Forest, the out-of-the-box values give a mean abs error just below 4 Farenheit (although the errors coming out of the cross-validation show less variance on repeated runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "df9d08ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-4.17764297, -3.77253216, -3.62568237, -4.34194688, -3.7586422 ]), -3.9352893155416284)\n"
     ]
    }
   ],
   "source": [
    "regr = HistGradientBoostingRegressor()\n",
    "scores = utils.get_cross_val_scores(regr, X, y, 5)\n",
    "print((scores, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768736d9",
   "metadata": {},
   "source": [
    "Tweaking parameters to pull the trees back from overfitting yields some slight performance improvements as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8e10b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-3.86177589, -3.67483445, -3.70281161, -3.61859548, -4.03036255]), -3.777675997142036)\n"
     ]
    }
   ],
   "source": [
    "regr = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    max_iter=100,\n",
    "    max_leaf_nodes=None,\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=10,\n",
    "    l2_regularization=0,\n",
    "    max_bins=255,\n",
    "    categorical_features=None,\n",
    "    monotonic_cst=None,\n",
    "    early_stopping=\"auto\",\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    "    tol=1.0e-4\n",
    ")\n",
    "scores = utils.get_cross_val_scores(regr, X, y, 5)\n",
    "print((scores, np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
