{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671a0669",
   "metadata": {},
   "source": [
    "# Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f62e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import copy\n",
    "import shap\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b1b286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "348"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "df = utils.get_data()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5517a816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(348, 3)\n",
      "(348,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df[[\"temp_2\", \"temp_1\", \"average\"]])\n",
    "y = np.array(df[\"actual\"])\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e179fb56",
   "metadata": {},
   "source": [
    "### Standard Gradient Boosted trees\n",
    "Based off XGBoost. As for Random Forest, the out-of-the-box values give a mean abs error just below 4 Farenheit (although the errors coming out of the cross-validation show less variance on repeated runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d7c785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-4.65454863, -4.11422532, -3.49592022, -3.82909805, -4.01827258]), -4.022412958898516)\n"
     ]
    }
   ],
   "source": [
    "regr = GradientBoostingRegressor()\n",
    "scores = utils.get_cross_val_scores(regr, X, y, 5)\n",
    "print((scores, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba1f86",
   "metadata": {},
   "source": [
    "Tweaking parameters (e.g. min_samples_leaf, min_samples_split) to pull the trees back from overfitting yields some slight performance improvements as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718056df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-4.6863613 , -3.44053954, -3.49802911, -3.9556169 , -3.52534958]), -3.821179286887902)\n"
     ]
    }
   ],
   "source": [
    "regr = GradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=1.0,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=10,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_depth=3,\n",
    "    min_impurity_decrease=0.0,\n",
    "    max_features=None,\n",
    "    alpha=0.9,\n",
    "    max_leaf_nodes=None,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=None,\n",
    "    tol=1.0e-4,\n",
    "    ccp_alpha=0.0\n",
    ")\n",
    "scores = utils.get_cross_val_scores(regr, X, y, 5)\n",
    "print((scores, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0579fd4",
   "metadata": {},
   "source": [
    "### LightGBM Gradient Boosted Trees\n",
    "Based on LightGBM. As for Random Forest, the out-of-the-box values give a mean abs error just below 4 Farenheit (although the errors coming out of the cross-validation show less variance on repeated runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df9d08ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-3.51845481, -4.22037392, -3.76393088, -3.73469817, -3.98598955]), -3.8446894674118197)\n"
     ]
    }
   ],
   "source": [
    "regr = HistGradientBoostingRegressor()\n",
    "scores = utils.get_cross_val_scores(regr, X, y, 5)\n",
    "print((scores, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768736d9",
   "metadata": {},
   "source": [
    "Tweaking parameters to pull the trees back from overfitting yields some slight performance improvements as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e10b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-3.9521812 , -3.41632257, -4.2550038 , -3.95979037, -3.81842395]), -3.8803443790349705)\n"
     ]
    }
   ],
   "source": [
    "regr = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.1,\n",
    "    max_iter=100,\n",
    "    max_leaf_nodes=None,\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=10,\n",
    "    l2_regularization=0,\n",
    "    max_bins=255,\n",
    "    categorical_features=None,\n",
    "    monotonic_cst=None,\n",
    "    early_stopping=\"auto\",\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    "    tol=1.0e-4\n",
    ")\n",
    "scores = utils.get_cross_val_scores(regr, X, y, 5)\n",
    "print((scores, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e41fe",
   "metadata": {},
   "source": [
    "### Tweaking hyperparams with grid search\n",
    "\n",
    "We can try and see if there is any mileage in tweaking the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e014931",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = utils.get_train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "99590d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=HistGradientBoostingRegressor(max_iter=25),\n",
       "             param_grid={'l2_regularization': [0, 1],\n",
       "                         'learning_rate': [0.07, 0.1, 0.13, 0.17],\n",
       "                         'max_depth': [4, 6, 8, 10],\n",
       "                         'max_leaf_nodes': [10, 12, 15],\n",
       "                         'min_samples_leaf': [10, 12, 15, 20]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = HistGradientBoostingRegressor(max_iter=25)\n",
    "grid_values = {\n",
    "    \"learning_rate\": [0.07, 0.1, 0.13, 0.17],\n",
    "    \"max_leaf_nodes\": [10, 12, 15],\n",
    "    \"max_depth\": [4,6,8,10],\n",
    "    \"min_samples_leaf\": [10, 12, 15, 20],\n",
    "    \"l2_regularization\": [0,1],\n",
    "}\n",
    "grid_regr_acc = GridSearchCV(regr, param_grid = grid_values,scoring = 'neg_mean_squared_error')\n",
    "grid_regr_acc.fit(X_train, y_train)  # this will use a default CV scheme on the training data of 5-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24ee9980",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HistGradientBoostingRegressor(l2_regularization=1, learning_rate=0.13,\n",
       "                              max_depth=8, max_iter=25, max_leaf_nodes=10,\n",
       "                              min_samples_leaf=12)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_regr_acc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c034135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-3.49763578, -4.46351324, -3.89038819, -3.88515278, -3.62760239]), -3.872858476134982)\n"
     ]
    }
   ],
   "source": [
    "scores = utils.get_cross_val_scores(grid_regr_acc.best_estimator_, X_train, y_train, 5)\n",
    "print((scores, np.mean(scores)))\n",
    "# this will test against most of the data used to train over the grid search; \n",
    "# so effectively the performance on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09ce32af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-4.19739768, -4.10158286, -4.32926636, -4.65390794, -3.36886148]), -4.130203264458821)\n"
     ]
    }
   ],
   "source": [
    "scores = utils.get_cross_val_scores(grid_regr_acc.best_estimator_, X_test, y_test, 5)\n",
    "print((scores, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ef819",
   "metadata": {},
   "source": [
    "Even with a search, the performance does not really improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
